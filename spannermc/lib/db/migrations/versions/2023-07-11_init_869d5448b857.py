# type: ignore

"""init

Revision ID: 869d5448b857
Revises: 
Create Date: 2023-07-11 02:12:09.331120

"""
import warnings

import sqlalchemy as sa
from alembic import op
from litestar.contrib.sqlalchemy.types import GUID, ORA_JSONB, DateTimeUTC


__all__ = ["downgrade", "upgrade", "schema_upgrades", "schema_downgrades", "data_upgrades", "data_downgrades"]

sa.GUID = GUID
sa.DateTimeUTC = DateTimeUTC
sa.ORA_JSONB = ORA_JSONB

# revision identifiers, used by Alembic.
revision = '869d5448b857'
down_revision = None
branch_labels = None
depends_on = None


def upgrade():
    with warnings.catch_warnings():
        warnings.filterwarnings("ignore", category=UserWarning)
        with op.get_context().autocommit_block():
            schema_upgrades()
            data_upgrades()

def downgrade():
    with warnings.catch_warnings():
        warnings.filterwarnings("ignore", category=UserWarning)
        with op.get_context().autocommit_block():
            data_downgrades()
            schema_downgrades()

def schema_upgrades():
    """schema upgrade migrations go here."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('user_account',
    sa.Column('email', sa.String(), nullable=False),
    sa.Column('name', sa.String(), nullable=True),
    sa.Column('hashed_password', sa.String(length=255), nullable=True),
    sa.Column('is_active', sa.Boolean(), nullable=False),
    sa.Column('is_superuser', sa.Boolean(), nullable=False),
    sa.Column('is_verified', sa.Boolean(), nullable=False),
    sa.Column('verified_at', sa.DateTimeUTC(timezone=True), nullable=True),
    sa.Column('id', sa.GUID(length=16), nullable=False),
    sa.Column('sa_orm_sentinel', sa.Integer(), nullable=True),
    sa.Column('created_at', sa.DateTimeUTC(timezone=True), nullable=False),
    sa.Column('updated_at', sa.DateTimeUTC(timezone=True), nullable=False),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_user_account')),
    comment='User accounts for application access'
    )
    with op.batch_alter_table('user_account', schema=None) as batch_op:
        batch_op.create_index('uk_user_account_email', ['email'], unique=True)

    op.create_table('event',
    sa.Column('message', sa.String(), nullable=False),
    sa.Column('user_id', sa.GUID(length=16), nullable=False),
    sa.Column('id', sa.GUID(length=16), nullable=False),
    sa.Column('sa_orm_sentinel', sa.Integer(), nullable=True),
    sa.Column('created_at', sa.DateTimeUTC(timezone=True), nullable=False),
    sa.Column('updated_at', sa.DateTimeUTC(timezone=True), nullable=False),
    sa.ForeignKeyConstraint(['user_id'], ['user_account.id'], name=op.f('fk_event_user_id_user_account')),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_event')),
    comment='Events'
    )
    # ### end Alembic commands ###

def schema_downgrades():
    """schema downgrade migrations go here."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('event')
    with op.batch_alter_table('user_account', schema=None) as batch_op:
        batch_op.drop_index('uk_user_account_email')

    op.drop_table('user_account')
    # ### end Alembic commands ###

def data_upgrades():
    """Add any optional data upgrade migrations here!"""
    pass

def data_downgrades():
    """Add any optional data downgrade migrations here!"""
    pass